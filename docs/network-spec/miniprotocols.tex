\chapter{Mini Protocols}
\label{chapter:mini-protocols}

\newcommand{\Client}{\textcolor{mygreen}{\textbf{Client}}}
\newcommand{\Server}{\textcolor{myblue}{\textbf{Server}}}

\section{Mini Protocols and Protocol Families}https://hackage.haskell.org/package/typed-protocols-doc
A mini protocol is a well-defined and modular building block of
the network protocol.
Structuring a protocol around mini-protocols helps manage the overall complexity of
the design and adds useful flexibility.
The design turns into a family of mini-protocols that can be specialised to particular requirements
by choosing a particular set of mini-protocols.

The mini-protocols in this section describe the initiator and responder of a communication.
The initiator is the dual of the responder and vice versa.
(The terms client/server, consumer/producer or initiator/responder are also used sometimes.)
At any time, a node will typically run many instances of mini-protocols, including many instances of the
same mini-protocol.
Each mini-protocol instance of the node communicates with the dual instance of
exactly one peer.

The set of mini protocols that run on a connection between two participants of the system
depends on the role of the participants, i.e. whether the node acts as a full node or just
a blockchain consumer, such as a wallet.

\section{Protocols as State Machines}
The implementation of the mini protocols uses a generic framework for state machines.
This framework uses correct-by-construction techniques to guarantee
several properties of each mini-protocol.
In particular, it guarantees that there are no deadlocks.
At any time, only one side has the agency
(is expected to transmit the next message) while the other side is waiting for
the message (or both sides agree that the mini-protocol has terminated).
If either side receives a message that is not expected according to the mini-protocol
the communication is aborted (the connection is closed).

For each mini-protocol based on this underlying framework, the description provides the
following pieces of information:

\begin{itemize}
\item An informal description of the mini-protocol.
\item States of the state machine.
\item The messages (transitions) of the mini-protocol.
\item A transition graph of the global view of the state machine.
\item The client implementation of the mini-protocol.
\item The server implementation of the mini-protocol.
\end{itemize}

\begin{description}
\item[State Machine]
  Each mini-protocol is described as a state machine.
  This document uses simple diagram representations for state machines and
  also includes corresponding transition tables.
  Descriptions of state machines in this section are directly derived from
  specifications of mini protocols using the state machine framework.

  The state machine framework that is used to specify the mini-protocol can be instantiated
  with different implementations that work at different levels of abstraction
  (for example, implementations used for simulation, implementations that run over virtual
  connections and implementations that actually transmit messages over the real network).


\item[States]
  States are abstract: they are not a value of some variables in a node, but
  rather describe the state of the two-party communication as a whole, e.g.
  that a client is responsible for sending a particular type of message and
  the server is waiting on it.  This, in particular, means that if the state
  machine is in a given state, then both the client and server are in this state.
  An additional piece of information that differentiates the roles of peers in
  a given state is the agency, which describes which side is responsible for
  sending the next message.

  In the state machine framework, abstract states of a state machine are
  modelled as promoted types, so they do not correspond to any particular
  the value held by one of the peers.

  The document presents this abstract view of mini protocols and the state
  machines where the client and server are always in identical states, which
  also means that the client and server simultaneously transit to new states.
  For this description, network delays are not important.

  An interpretation which is closer to the real-world implementation but
  less concise is that there are independent client and server states
  and that transitions on either side happen independently when a message is sent or received.

\item[Messages]
  Messages exchanged by peers form edges of a state machine diagram; in other
  words, they are transitions between states.
  They are elements from the set
  $$\{(label, data) \mid label \in Labels, data \in Data\}$$
  Protocols use a small set of $Labels$ typically $|Labels| \leq 10$.
  The state machine framework requires that messages can be serialised,
  transferred over the network and de-serialised by the receiver.

\item[Agency]
  A node has agency if it is expected to send the next message.
  The client or server has agency in every state, except a termination state in which nor the client, nor the server can send any message. All our mini-protocols have a single terminating state \StDone{}.

\item [State machine diagrams]
      States are drawn as circles in state machine diagrams.
      States with the agency on the client side are drawn in green, states with the agency on the server side are drawn in blue, and
      the termination states are in black.
      By construction, the system is always in exactly one state,
      i.e. the client's state is always the same state as the server's,
      and the colour indicates who the agent is.
      It is also important to understand that the arrows in the state transition diagram denote
      state transitions and not the direction of the message that is being transmitted.
      For the agent of the particular state, the arrow means: ``send a message to the
      other peer and move to the next state''.
      For a non-agent, an arrow in the diagram can be interpreted as:
      ``receive an incoming message and move to the next state''.
      This may not be very clear because the arrows are labelled with the messages, and
      many arrows go from a green state (the client has the agency) to a blue
      state (the server has the agency) or vice versa.

\begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, mygreen]              (A)      {$A$};
  \node[state, myblue ,right of=A]   (B)      {$B$};
  \draw (A)            edge[above]          node{Message}   (B);
\end{tikzpicture}

      $A$ is green, i.e in state $A$ the client has agency.
      Therefore, the client sends a message to the server and
      both client and server transition to state $B$.
      As $B$ is blue, the agency also changes from client to server.

\begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, myblue]               (C)      {$C$};
  \node[state, myblue ,right of=A]   (D)      {$D$};
  \draw (A)            edge[above]               node{Message}   (B);
\end{tikzpicture}

      $C$ is blue, i.e in state $C$ the server has agency.
      Therefore, the server sends a message to the client and
      both client and server transition to state $D$.
      As $D$ is also blue, the agency remains on the server.

\item[Client and server implementation]
  The state machine describes which messages are sent and received and in which order.
  This is the external view of the protocol that every compatible implementation MUST follow.
  In addition to the external view of the protocol, this part of the specification describes
  how the client and server actually process the transmitted messages,
  i.e. how the client and server update their internal mutable state
  upon the exchange of messages.

  Strictly speaking, the representation of the node-local mutable state
  and the updates to the node-local state are implementation details that are
  not part of the communication protocol between the nodes and will
  depend on an application that is built on top of the network service
  (wallet, core node, explorer, etc.).
  The corresponding sections were added to clarify the mode of operation of the
  mini protocols.

\end{description}
\section{Overview of all implemented Mini Protocols}

\newcommand{\miniEntry}[5]{
  \begin{framed}
      \noindent\textbf{#1}\hfill  Section \ref{#2}
      \newline {#3}
      \newline {\href{#5}{\small\texttt{#4}}}
  \end{framed}
}

\subsection{Dummy mini-protocols}

Dummy mini-protocols are not used by `cardano-node`; however, they might be
helpful when writing demos, testing purposes or getting familiar with the
framework.

\miniEntry
    {Ping Pong Protocol}
    {ping-pong-protocol}
    {A simple ping-pong protocol for testing.}
    {typed-protocols/src/Network/TypedProtocol/PingPong/Type.hs}
    {https://input-output-hk.github.io/typed-protocols/typed-protocols-examples/Network-TypedProtocol-PingPong-Type.html\#t:PingPong}

\miniEntry
    {Request Response Protocol}
    {request-response-protocol}
    {A ping-pong-like protocol which allows the exchange of data.}
    {typed-protocols/src/Network/TypedProtocol/ReqResp/Type.hs}
    {https://input-output-hk.github.io/typed-protocols/typed-protocols-examples/Network-TypedProtocol-ReqResp-Type.html\#t:ReqResp}

\subsection{Handshake}

Handshake mini-protocol is shared by the node-to-node and node-to-client
protocols (it is polymorphic to allow that).

\miniEntry
    {Handshake Mini Protocol}
    {handshake-protocol}
    {This protocol is used for version negotiation.}
    {ouroboros-network/framework/lib/Ouroboros/Network/Protocol/Handshake/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/framework/Ouroboros-Network-Protocol-Handshake-Type.html\#t:Handshake}

\subsection{Node-to-node mini-protocols}

In this section, we list all the mini-protocols that constitute the node-to-node protocol.

\miniEntry
    {Chain Synchronisation Protocol}
    {chain-sync-protocol}
    {The protocol by which a downstream chain consumer follows an upstream chain producer.}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/ChainSync/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-ChainSync-Type.html\#t:ChainSync}

\miniEntry
    {Block Fetch Protocol}
    {block-fetch-protocol}
    {The block fetching mechanism enables a node to download ranges of blocks.}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/BlockFetch/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-BlockFetch-Type.html\#t:BlockFetch}

\miniEntry
    {Transaction Submission Protocol v2}
    {tx-submission-protocol2}
    {A Protocol for transmitting transactions between core nodes.}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/TxSubmission2/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-TxSubmission2-Type.html\#t:TxSubmission2}

\miniEntry
    {Keep Alive Protocol}
    {keep-alive-protocol}
    {A protocol for sending keep alive messages and doing round trip measurements}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/KeepAlive/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-KeepAlive-Type.html\#t:KeepAlive}

\miniEntry
    {Peer Sharing Protocol}
    {peer-sharing-protocol}
    {A mini-protocol which allows to share peer addresses}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/PeerSharing/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-PeerSharing-Type.html\#t:PeerSharing}

\subsection{Node-to-client mini-protocols}

Mini-protocols used by node-to-client protocol.  The chain-sync mini-protocol
is shared between node-to-node and node-to-client protocols, but it is instantiated differently.  In
node-to-client protocol, it is used with full blocks rather than just headers.

\miniEntry
    {Chain Synchronisation Protocol}
    {chain-sync-protocol}
    {The protocol by which a downstream chain consumer follows an upstream chain producer.}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/ChainSync/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-ChainSync-Type.html\#t:ChainSync}

\miniEntry
    {Local State Query Mini Protocol}
    {local-state-query-protocol}
    {Protocol used by local clients to query ledger state}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/LocalStateQuery/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/cardano-diffusion/protocols/Cardano-Network-Protocol-LocalStateQuery-Type.html\#t:LocalStateQuery}

\miniEntry
    {Local Tx Submission Mini Protocol}
    {local-tx-submission-protocol}
    {Protocol used by local clients to submit transactions}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/LocalTxSubmission/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-LocalTxSubmission-Type.html\#t:LocalTxSubmission}

\miniEntry
    {Local Tx Monitor Mini Protocol}
    {local-tx-monitor-protocol}
    {Protocol used by local clients to monitor transactions}
    {ouroboros-network/protocols/lib/Ouroboros/Network/Protocol/LocalTxMonitor/Type.hs}
    {https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network/protocols/Ouroboros-Network-Protocol-LocalTxMonitor-Type.html\#t:LocalTxMonitor}


\section{CBOR and CDDL}
All mini-protocols are encoded using the concise binary object representation
(CBOR), see~\url{https://cbor.io}.  Each codec comes along with a specification
written in CDDL,
see \href{https://cbor-wg.github.io/cddl/draft-ietf-cbor-cddl.html}{'Coincise
data definition language (CDDL)'}.

The networking layer knows little about blocks, transactions or
their identifiers.  In \texttt{ouroboros-network} we use parametric
polymorphism for blocks, tx, txids, etc, and we only assume these data types have their own valid CDDL
encoding (and CDDL specifications).  For testing against the \texttt{ouroboros-network} CDDL, we need
concrete values; for this reason, we use \texttt{any} in our CDDL specification.
This describes very closely what the \texttt{ouroboros-network} implementation
does.  It doesn't mean the payloads are not validated, the full codecs of
messages transferred on the wire are composed from network, consensus \& ledger
codecs.   There is an ongoing effort to capture combined CDDLs.  If you want to
find concrete instantiations of these types by `Cardano`, you will need to
consult
\href{https://github.com/intersectmbo/cardano-ledger}{cardano-ledger} and
\href{https://github.com/intersectmbo/ouroboros-consensus}{ouroboros-consensus} (in particular \href{https://github.com/IntersectMBO/ouroboros-consensus/pull/1422}{ouroboros-consensus\#1422}).
Each ledger era has its own CDDL spec, which you can find
\href{https://github.com/intersectmbo/cardano-ledger#cardano-ledger}{here}.
Note that the hard fork combinator (HFC) also allows us to
combine multiple eras into a single blockchain.  It affects how many of the
data types are encoded across different eras.

We want to retain the ability to decode messages incrementally, which for the
Praos protocol might allow us to improve performance.

\section{Dummy Protocols}
Dummy protocols are only used for testing and are not needed either for
Node-to-Node nor for the Node-to-Client protocols.
\subsection{Ping-Pong mini-protocol}
\label{ping-pong-protocol}
\haddockrefraw{Network.TypedProtocol.PingPong.Type}{https://input-output-hk.github.io/typed-protocols/typed-protocols-examples/Network-TypedProtocol-PingPong-Type.html\#t:PingPong}
\newcommand{\Ping}{\msg{MsgPing}}
\newcommand{\Pong}{\msg{MsgPong}}


\subsubsection{Description}
A client can use the Ping-Pong protocol to check that the server is responsive.
The Ping-Pong protocol is very simple because the messages do not carry any data and
because the Ping-Pong client and the Ping-Pong server do not access the internal state of the node.

\subsubsection{State Machine}
\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]      (Idle) {\StIdle};
    \node[state, right of=Idle]         (Done) {\StDone};
    \node[state, myblue, below of=Idle] (Busy) {\StBusy};

    \draw (Idle) edge[above]             node{\MsgDone} (Done);
    \draw (Idle) edge[left, bend right]  node{\Ping}    (Busy);
    \draw (Busy) edge[right, bend right] node{\Pong}    (Idle);
  \end{tikzpicture}
\end{figure}

\begin{figure}[ht]
  \begin{tabular}{l|l}
    \header{state} & \header{agency} \\\hline
    \StIdle        & \Client \\
    \StBusy        & \Server \\
  \end{tabular}
\end{figure}

The protocol uses the following messages.
The messages of the Ping-Pong protocol do not carry any data.
\begin{description}
\item [\Ping]
      The client sends a Ping request to the server.
\item [\Pong]
      The server replies to a Ping with a Pong.
\item [\MsgDone]
      Terminate the protocol.
\end{description}

\begin{table}[h]
  \begin{tabular}{l|l|l}
    \header{from state} & \header{message} & \header{to state} \\\hline
    \StIdle             & \Ping            & \StBusy  \\
    \StBusy             & \Pong            & \StIdle  \\
    \StIdle             & \MsgDone         & \StDone  \\
  \end{tabular}
  \caption{Ping-Pong mini-protocol messages.}
\end{table}

\subsection{Request-Response mini-protocol}
\label{request-response-protocol}
\haddockrefraw{Network.TypedProtocol.ReqResp.Type}{https://input-output-hk.github.io/typed-protocols/typed-protocols-examples/Network-TypedProtocol-ReqResp-Type.html\#t:ReqResp}
\renewcommand{\StIdle}{\state{StIdle}}
\renewcommand{\StBusy}{\state{StBusy}}
\renewcommand{\StDone}{\state{StDone}}
\newcommand{\Request}{\msg{MsgReq}}
\newcommand{\Response}{\msg{MsgResp}}
\newcommand{\RespDone}{\msg{MsgDone}}

\subsubsection{Description}
The request-response protocol is polymorphic in the request and response data that is being transmitted.
This means that there are different possible applications of this protocol, and the
application of the protocol determines the types of requests and responses.

\subsubsection{State machine}
\begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, mygreen, initial]      (Idle) {\StIdle};
  \node[state, myblue, right of=Idle] (Busy) {\StBusy};
  \node[state, below of=Idle]         (Done) {\StDone};

  \draw (Idle) edge[below, bend right] node{\Request}  (Busy);
  \draw (Busy) edge[above, bend right] node{\Response} (Idle);
  \draw (Idle) edge[right]             node{\RespDone} (Done);
\end{tikzpicture}

\begin{figure}[ht]
  \begin{tabular}{l|l}
    \header{state} & \header{agency} \\\hline
    \StIdle        & \Client \\
    \StBusy        & \Server \\
  \end{tabular}
\end{figure}

The protocol uses the following messages.
\begin{description}
\item [\Request{} $(request)$]
      The client sends a request to the server.
\item [\Response{} $(response)$]
      The server replies with a response.
\item [\RespDone{} $(done)$]
      Terminate the protocol.
\end{description}

\begin{table}[h]
  \begin{tabular}{l|l|l|l}
    \header{from} & \header{message} & \header{parameters} & \header{to} \\\hline
    \StIdle       & \Request         & $request$           & \StBusy \\
    \StBusy       & \Response        & $response$          & \StIdle \\
    \StIdle       & \RespDone        &                     & \StDone \\
  \end{tabular}
  \caption{Request-Response mini-protocol messages.}
\end{table}

\section{Handshake mini-protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.Handshake.Type}{ouroboros-network/framework/Ouroboros-Network-Protocol-Handshake-Type.html\#t:Handshake}\\
\codechaddockref{Ouroboros.Network.Protocol.Handshake.Codec}{ouroboros-network/framework/Ouroboros-Network-Protocol-Handshake-Codec.html\#v:codecHandshake}\\
\hyperref[table:node-to-node-protocol-numbers]{\textit{node-to-node mini-protocol number}}: \texttt{0}\\
\hyperref[table:node-to-client-protocol-numbers]{\textit{node-to-client mini-protocol number}}: \texttt{0}\\
\hyperref[sec:nodetoclientcddl]{node-to-client handshake CDDL spec}
\label{handshake-protocol}

\newcommand{\StPropose}{\state{StPropose}}
\newcommand{\StConfirm}{\state{StConfirm}}
\newcommand{\MsgProposeVersions}{\msg{MsgProposeVersions}}
\newcommand{\MsgReplyVersions}{\msg{MsgReplyVersion}}
\newcommand{\MsgAcceptVersion}{\msg{MsgAcceptVersion}}
\newcommand{\MsgRefuse}{\msg{MsgRefuse}}

\newcommand{\VersionMismatch}{\msg{VersionMismatch}}
\newcommand{\HandshakeDecodeError}{\msg{HandshakeDecodeError}}
\newcommand{\Refused}{\msg{Refused}}

\subsection{Description}
The handshake mini protocol is used to negotiate the protocol version
and the protocol parameters that are used by the client and the server.
It is run exactly once when a new connection is initialised
and consists of a single request from the client and a single reply from the server.

The handshake mini protocol is a generic protocol that can negotiate version number and protocol parameters (these my depend on the version number).
It only assumes that protocol parameters can be encoded to and decoded from CBOR terms.
A node that runs the handshake protocol must instantiate it with the set of
supported protocol versions and callback functions to handle the protocol parameters.
These callback functions are specific to the supported protocol versions.

The handshake mini protocol is designed to handle simultaneous TCP open.

\subsection{State machine}
\begin{figure}[h]
  \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=6cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]   (StPropose) at (0,  0) {\StPropose};
    \node[state, myblue]             (StConfirm) at (5,  0) {\StConfirm};
    \node[state, right of=Confirm]   (StDone)    at (7,  0) {\StDone};

    \draw (StPropose) --node[above=1em]{\MsgProposeVersions} (StConfirm);
    \draw[->] (StConfirm.10)  to [out=15,  in=150] node[above]{\MsgAcceptVersion} (StDone.170);
    \draw[->] (StConfirm.350) to [out=-15, in=210] node[below]{\MsgRefuse}        (StDone.190);
    \draw[->] (StConfirm)     -- node[fill=white,above=-0.8em]{\MsgReplyVersions} (StDone.west);
  \end{tikzpicture}
\end{figure}

\begin{figure}[h]
  \begin{tabular}{l|l}
    \header{state} & \header{agency} \\\hline
    \StPropose     & \Client \\
    \StConfirm     & \Server \\
  \end{tabular}
\end{figure}

Messages of the protocol:
\begin{description}
  \item [\MsgProposeVersions{} {\boldmath $(versionTable)$}]
      The client proposes a number of possible versions and protocol parameters.
      $versionTable$ is a map from version numbers to their associated version
      data.  Note that different version numbers might use different version
      data (e.g. supporting a different set of parameters).
  \item [\MsgReplyVersions{} {\boldmath $(versionTable)$}]
      This message must not be explicitly sent, it's only to support TCP
      simultaneous open scenario in which both sides sent
      \MsgProposeVersions{}.  In this case, the received \MsgProposeVersions{}
      is interpreted as \MsgReplyVersions{} and thus it MUST have the same CBOR
      decoding as \MsgProposeVersions{}.
  \item [\MsgAcceptVersion{} {\boldmath $(versionNumber,extraParameters)$}]
      The server accepts $versionNumber$ and returns possible extra protocol parameters.
  \item [\MsgRefuse{} {\boldmath $(reason)$}]
      The server refuses the proposed versions.
\end{description}

{\small
\begin{table}[h]
  \begin{tabular}{l|l|l|l}
    \header{from} & \header{message} & \header{parameters} & \header{to} \\\hline
    \StPropose & \MsgProposeVersions & $versionTable$                & \StConfirm \\
    \StConfirm & \MsgReplyVersions   & $versionTable$                & \StDone \\
    \StConfirm & \MsgAcceptVersion   & $(versionNumber,versionData)$ & \StDone \\
    \StConfirm & \MsgRefuse          & $reason$                      & \StDone \\
  \end{tabular}
\end{table}
}

\subsection{Size limits per state}

These bounds limit how many bytes can be sent in a given state; indirectly, this
limits the payload size of each message.  If a space limit is violated, the
connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StPropose & \texttt{5760} \\
      \StConfirm & \texttt{5760} \\
    \end{tabular}
    % \caption{size limits per state}
    \label{table:handshake-size-limits}
  \end{center}
\end{table}

\subsection{Timeouts per state}

These limits bound how much time the receiver side can wait for the arrival of
a message.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{timeout} \\\hline
      \StPropose     & \texttt{10}s \\
      \StConfirm     & \texttt{10}s \\
    \end{tabular}
    \caption{timeouts per state}
    \label{table:handshake-timeouts}
  \end{center}
\end{table}

\subsection{Node-to-node handshake}
\codechaddockref{Cardano.Network.NodeToNode}{cardano-diffusion/Cardano-Network-NodeToNode.html\#v:nodeToNodeHandshakeCodec}\\

The node-to-node handshake instantiates version data\footnote{To be precise, in
ouroboros-network, we instantiate version data to CBOR terms and do encoding
/ decoding of version data lazily (as required) rather than as part of the
protocol codec (the protocol codec only decodes bytes to CBOR terms, and thus
fails only if received bytes are not a valid CBOR encoding).  This is important
in order to support receiving a mixture of known and unknown versions. The same
the remark applies to the node-to-client protocol as well.} to a record which consists
of
\begin{description}
  \item[network magic] a \texttt{Word32} value;
  \item[diffusion mode] a boolean value: \texttt{True} value indicates
    initiator only mode, \texttt{False} - initiator and responder mode;
  \item[peer sharing] either $0$ or $1$: $1$ indicates that the node
    will engage in peer sharing (and thus it will run the PeerSharing
    mini-protocol);
  \item[query] a boolean value: \texttt{True} will send back all supported
    versions \& version data and terminate the connection.
\end{description}

When negotiating a connection, each side will have access to local and remote
version data associated with the negotiated version number.  The result of
negotiation is a new version data record which consists of:
\begin{itemize}\label{alg:node-to-node-negotiation}
  \item if the network magic agrees, then it is inherited by the negotiated version
    data, otherwise the negotiation fails;
  \item diffusion mode SHOULD be initiator only if and only if any side proposes the
    initiator-only mode (i.e. the logical disjunction operator);
  \item peer sharing SHOULD be inherited from the remote side;
  \item query SHOULD be inherited from the client (the side that sent
      \MsgProposeVersions{}).
\end{itemize}
If the negotiation is successful, the negotiated version data is sent back
using \MsgAcceptVersion{}, otherwise \MsgRefuse{} SHOULD be sent.

\subsubsection{Size limits per state}

These bounds limit how many bytes can be sent in a given state; indirectly, this
limits the payload size of each message.  If a space limit is violated, the
connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StPropose & \texttt{5760} \\
      \StConfirm & \texttt{5760} \\
    \end{tabular}
    % \caption{size limits per state}
  \end{center}
\end{table}

\subsubsection{Timeouts per state}

These limits bound how much time the receiver side can wait for the arrival of
a message.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{timeout} \\\hline
      \StPropose     & \texttt{10}s \\
      \StConfirm     & \texttt{10}s \\
    \end{tabular}
    % \caption{timeouts per state}
  \end{center}
\end{table}

\subsection{Node-to-client handshake}
\codechaddockref{Cardano.Network.NodeToClient}{cardano-diffusion/Cardano-Network-NodeToClient.html\#v:nodeToClientHandshakeCodec}\\

The node-to-node handshake instantiates version data to a record which consists
of
\begin{description}
  \item[network magic] a \texttt{Word32} value;
  \item[query] a boolean value: \texttt{True} will send back all supported;
    versions \& version data and terminate the connection.
\end{description}

The negotiated version data is computed similarly as in the node-to-node
protocol:
\begin{itemize}\label{alg:node-to-client-negotiation}
  \item if the network magic agrees, then it is inherited by the negotiated version
    data, otherwise the negotiation fails;
  \item query SHOULD be inherited from the client (the side that sent
    \MsgProposeVersions{}).
\end{itemize}
If the negotiation is successful, the negotiated version data is sent back
using \MsgAcceptVersion{}, otherwise \MsgRefuse{} SHOULD be sent.

\subsubsection{Size limits per state}

These bounds limit how many bytes can be sent in a given state; indirectly, this
limits the payload size of each message.  If a space limit is violated, the
connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StPropose & \texttt{5760} \\
      \StConfirm & \texttt{5760} \\
    \end{tabular}
    % \caption{size limits per state}
  \end{center}
\end{table}

\subsubsection{Timeouts per state}

No timeouts are used for node-to-client handshake.

\subsection{Client and Server Implementation}
Section~\ref{handshake-cddl} contains the CDDL specification of the binary format of the handshake messages.
The version table is encoded as a CBOR table with the version number as the key
and the protocol parameters as a value.
The handshake protocol requires that the version numbers ( i.e. the keys) in the version table are unique
and appear in ascending order.
(Note that CDDL is not expressive enough to precisely specify that requirement on the keys of the CBOR
table. Therefore, the CDDL specification uses a table with keys from 1 to 4 as an example.)

In a run of the handshake mini protocol, the peers exchange only two messages:
The client initiates the protocol with a \MsgProposeVersions{} message that
contains information about all protocol versions it wants to support. The
server replies either with an \MsgAcceptVersion{} message containing the
negotiated version number and version data or a \MsgRefuse{} message.
The \MsgRefuse{} message contains one of three alternative refuse reasons:
\VersionMismatch{}, \HandshakeDecodeError{} or just \Refused{}.

When a server receives a \MsgProposeVersions{} message, it uses the following algorithm to
compute the response:
\begin{enumerate}
\item
  Compute the intersection of the set of protocol version numbers that the server supports
  and the version numbers requested by the client.
\item
  If the intersection is empty:
  Reply with \MsgRefuse(\VersionMismatch) and the list of protocol numbers the server supports.
\item
  Otherwise, select the protocol with the highest version number in the
    intersection.
\item
  Run the protocol-specific decoder on the CBOR term that contains the protocol parameters.
\item
  If the decoder fails:
  Reply with \MsgRefuse(\HandshakeDecodeError), the selected version number and an error message.
\item
  Otherwise, test the proposed protocol parameters of the selected protocol version
\item
  If the test refuses the parameters:
    Reply with \MsgRefuse(\Refused), the selected version number and an error message.
\item
  Otherwise, compute negotiation parameters according to the
    algorithm~\ref{alg:node-to-node-negotiation} or
    \ref{alg:node-to-client-negotiation}, encode them with the corresponding
    CBOR codec and reply with \MsgAcceptVersion, the selected version number
    and the extra parameters.
\end{enumerate}
Note that in step 4), 6) and 8) the handshake protocol uses the callback functions that are specific
for a set of protocols that the server supports.
The handshake protocol is designed
so that a server can always handle requests for protocol versions that it does not support.
The server simply ignores the CBOR terms that represent the protocol parameters of unsupported
versions.

In case of simultaneous open of a TCP connection, both handshake clients will
send their \MsgProposeVersions{}, and both will interpret the incoming message as
\MsgReplyVersions{} (thus, both must have the same encoding; the implementation
can distinguish them by the protocol state).  Both clients should choose the
highest version of the protocol available.  If any side does not accept any
version (or its parameters), the connection can be reset.

The protocol does not forbid, nor could it detect a usage of
\MsgReplyVersions{} outside of TCP simultaneous open.  The process of
choosing between the proposed and received version must be symmetric in the
following sense.

\begin{description}
  \item[]
    We use \texttt{acceptable :: vData -> vData -> Accept vData}
    function to compute accepted version data from local and remote data,
    where
\begin{verbatim}
  data Accept vData = Accept vData
                    | Refuse Text
                    deriving Eq
\end{verbatim}
    See
    \href{https://ouroboros-network.cardano.intersectmbo.org/ouroboros-network-framework/Ouroboros-Network-Protocol-Handshake-Version.html#t:Acceptable}{ref}.
    Both \texttt{acceptable local remote} and \texttt{acceptable remote local}
    must satisfy the following conditions:
    \begin{itemize}
      \item if either of them accepts a version by returning \texttt{Accept},
        the other one must accept the same value, i.e. in this case
        \texttt{acceptable local remote == acceptable remote local}
      \item if either of them refuses to accept (returns \texttt{Refuse reason})
        the other one SHOULD return \texttt{Refuse} as well.
    \end{itemize}
\end{description}
Note that the above condition guarantees that if either side returns
\texttt{Accept}, then the connection will not be closed by the remote end.
A weaker condition, in which the return values are equal if they both return
\texttt{Accept} does not guarantee this property.  We also verify that the
whole Handshake protocol, not just the \texttt{acceptable} satisfies the above
property, see
\href{https://github.com/intersectmbo/ouroboros-network/blob/master/ouroboros-network/protocol-tests/Ouroboros/Network/Protocol/Handshake/Test.hs}{Ouroboros-Network
test suite}.

The fact that we are using non-injective encoding in the handshake protocol
side steps typed-protocols strong typed-checked properties.  For injective
codecs (i.e. codecs for which each message has a distinguished encoding), both
sides of typed-protocols are always in the same state (once all in-flight
the message arrived).  This is no longer true in general; however, this is still
true for the handshake protocol.  Even though the opening message
\MsgProposeVersions{} of a simultaneous open will materialise on the
other side as a termination message \MsgReplyVersions{}, and the same will
happen to the \MsgProposeVersions{} transmitted in the other direction.
We include a special test case
(\href{https://github.com/intersectmbo/ouroboros-network/blob/master/ouroboros-network/protocol-tests/Ouroboros/Network/Protocol/Handshake/Test.hs\#L551}{\texttt{prop\_channel\_simultaneous\_open}})
to verify that simultaneous open behaves well and does not lead to protocol
errors.

\subsection{Handshake and the multiplexer}

The handshake mini protocol runs before the multiplexer is initialised.
Each message is transmitted within a single MUX segment, i.e. with a proper
segment header, but as the multiplexer is not yet running, the messages MUST not
be split into multiple segments.  The Handshake protocol uses the
mini-protocol number $0$ in both node-to-node and node-to-client cases.

\subsection{CDDL encoding specification}\label{handshake-cddl}
There are two flavours of the mini-protocol that only differ with type
instantiations, e.g., different protocol versions and version data carried in
messages.  First, one is used by the node-to-node protocol, and the other is used by the
node-to-client protocol.
\subsubsection{Node-to-node handshake mini-protocol}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/handshake-node-to-node-v14.cddl}

\subsubsection{Node-to-client handshake mini-protocol}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/handshake-node-to-client.cddl}

\section{Chain-Sync mini-protocol}
\label{chain-sync-protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.ChainSync.Type}{ouroboros-network/protocols/Ouroboros-Network-Protocol-ChainSync-Type.html\#t:ChainSync}\\
\codechaddockref{Ouroboros.Network.Protocol.ChainSync.Codec}{ouroboros-network/protocols/Ouroboros-Network-Protocol-ChainSync-Codec.html\#v:codecChainSync}\\
\hyperref[table:node-to-node-protocol-numbers]{\textit{node-to-node mini-protocol number}}: \texttt{2}\\
\hyperref[table:node-to-client-protocol-numbers]{\textit{node-to-client mini-protocol number}}: \texttt{5}\\

\newcommand{\StCanAwait}{\state{StCanAwait}}
\newcommand{\StMustReply}{\state{StMustReply}}
\newcommand{\StIntersect}{\state{StIntersect}}
\newcommand{\MsgRequestNext}{\msg{MsgRequestNext}}
\newcommand{\MsgAwaitReply}{\msg{MsgAwaitReply}}
\newcommand{\MsgRollForward}{\msg{MsgRollForward}}
\newcommand{\MsgRollBackward}{\msg{MsgRollBackward}}
\newcommand{\MsgFindIntersect}{\msg{MsgFindIntersect}}
\newcommand{\MsgIntersectFound}{\msg{MsgIntersectFound}}
\newcommand{\MsgIntersectNotFound}{\msg{MsgIntersectNotFound}}

\subsection{Description}
The chain synchronisation protocol is used by a blockchain consumer
to replicate the producer's blockchain locally.
A node communicates with several upstream and downstream nodes
and runs an independent client instance and an independent server instance for every
other node it communicates with.
(See Figure~\ref{node-diagram-concurrency}.)

The chain synchronisation protocol is polymorphic.
The node-to-client protocol uses an instance of the chain synchronisation protocol
that transfers full blocks, while the node-to-node instance only transfers block headers.
In the node-to-node case, the block fetch protocol (Section \ref{block-fetch-protocol})
is used to diffuse full blocks.

\subsection{State Machine}

\begin{figure}[ht]
  \begin{tikzpicture}[->,auto,node distance=5.5cm,semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]                            (Idle)      {\StIdle};
    \node[state, right of=Idle]                               (Done)      {\StDone};
    \node[state, myblue, below left of=Idle]                  (CanAwait)  {\StCanAwait};
    \node[state, myblue, right of=CanAwait]                   (MustReply) {\StMustReply};
    \node[state, myblue, above of=Idle]                       (Intersect) {\StIntersect};

    \draw[->] (Idle.south west)  to[out=200, in=60]  node[fill=white, pos = 0.4, left=-10mm]{\MsgRequestNext}     (CanAwait.140);
    \draw[->] (CanAwait.270)     to[out=-40, in=230] node[fill=white, below]{\MsgAwaitReply}                      (MustReply.270);
    \draw (CanAwait.north east)  to[out=10, in=270]  node[fill=white, pos = 0.6, left=-7mm]{\MsgRollForward}      (Idle.230);
    \draw (CanAwait.south east)  to[out=10, in=270]  node[fill=white, pos = 0.5, right=-10mm]{\MsgRollBackward}   (Idle.305);
    \draw (MustReply.20)  to[out=60, in=0]           node[fill=white, pos = 0.5, right=-5mm]{\MsgRollBackward}    (Idle.20);
    \draw (MustReply.60)  to[out=60, in=0]           node[fill=white, pos = 0.4, left=-15mm]{\MsgRollForward}     (Idle.340);
    \draw (Idle)          edge[right, bend right]    node[fill=white, pos=0.3, left=-30mm]{\MsgFindIntersect}     (Intersect);
    \draw (Intersect.200) to[out=220, in=160]        node[fill=white, pos=0.3, left=-10mm]{\MsgIntersectNotFound} (Idle.160);
    \draw (Intersect.240) to[out=230, in=120]        node[fill=white, pos=0.6, left=-30mm]{\MsgIntersectFound}    (Idle.120);
    \draw (Idle)          edge[above]                node{\MsgDone}                                               (Done);
  \end{tikzpicture}
\caption{State machine of the Chain-Sync mini-protocol}
\label{chain-sync-automata}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StIdle        & \Client \\
      \StIntersect   & \Server \\
      \StCanAwait    & \Server \\
      \StMustReply   & \Server \\
    \end{tabular}
    \caption{Chain-Sync state agencies}
  \end{center}
\end{figure}


The protocol uses the following messages:
\begin{description}
\item [\MsgRequestNext]
      Request the next update from the producer.  The response can be a roll
      forward, a roll back or wait.
\item [\MsgAwaitReply]
      Acknowledge the request but require the consumer to wait for the next update.
      This means that the consumer is synced with the producer, and
      the producer is waiting for its own chain state to change.
\item [\MsgRollForward{} {\boldmath $(header, tip)$}]
      Tell the consumer to extend their chain with the given $header$.
      The message also tells the consumer about the $tip$ of the producer's chain.
\item [\MsgRollBackward{} {\boldmath $(point_{old}, tip$}]
      Tell the consumer to roll back to a given $point_{old}$ on their chain.
      The message also tells the consumer about the current  $tip$ of the chain the producer is following.
\item [\MsgFindIntersect{} {\boldmath $\langle point_{head} \rangle $}]
      Ask the producer to try to find an improved intersection point between
      the consumer and producer's chains.
      The consumer sends a sequence {\boldmath $\langle point \rangle $}, which
      shall be ordered by preference (e.g. points with the highest slot number
      first), and it is up to the producer to find the first intersection point
      on its chain and send it back to the consumer.  If an empty list of
      points is sent with \MsgFindIntersect{}, the server will reply with
      \MsgIntersectNotFound{}.
\item [\MsgIntersectFound{} {\boldmath $(point_{intersect} ,tip)$}]
      The producer replies with the first point of the request, which is on his current chain.
      The consumer can decide whether to send more points.
      The message also tells the consumer about the $tip$ of the producer.
      Whenever the server replies with \MsgIntersectFound{}, the client can
      expect the next update (i.e. a reply to \MsgRequestNext{}) to be
      \MsgRollBackward{}, either to the specified $point_{intersect}$ or an earlier
      point if the producer switched to a different fork in the meantime.
      This makes handling state updates on the client side easier.
\item [\MsgIntersectNotFound{} {\boldmath $(tip)$}]
      Reply to the consumer that no intersection was found: none of the
      points the consumer supplied are on the producer chain.
      The message only contains the $tip$ of the producer chain.
\item [\MsgDone]
      Terminate the protocol.
\end{description}

\begin{table}[h!]
  \begin{tabular}{l|l|l|l}
    \header{from state} & \header{message} & \header{parameters} & \header{to state}   \\\hline
    \StIdle      & \MsgRequestNext        &                             & \StCanAwait  \\
    \StIdle      & \MsgFindIntersect      & $\langle point\rangle$      & \StIntersect \\
    \StIdle      & \MsgDone               &                             & \StDone      \\
    \StCanAwait  & \MsgAwaitReply         &                             & \StMustReply \\
    \StCanAwait  & \MsgRollForward        & $header$, $tip$             & \StIdle      \\
    \StCanAwait  & \MsgRollBackward       & $point_{old}$, $tip$        & \StIdle      \\
    \StMustReply & \MsgRollForward        & $header$, $tip$             & \StIdle      \\
    \StMustReply & \MsgRollBackward       & $point_{old}$, $tip$        & \StIdle      \\
    \StIntersect & \MsgIntersectFound     & $point_{intersect}$, $tip$  & \StIdle      \\
    \StIntersect & \MsgIntersectNotFound  & $tip$                       & \StIdle      \\
  \end{tabular}
  \caption{Chain-Sync mini-protocol messages.}
\end{table}

\subsection{Node-to-node size limits per state}

Table~\ref {table:chain-sync-size-limits} specifies how many bytes can be sent
in a given state in the chain-sync mini-protocol of the node-to-node protocol;
indirectly, this limits the payload size of each message.  If a space limit is
violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StIdle        & \texttt{65535} \\
      \StCanAwait    & \texttt{65535} \\
      \StMustReply   & \texttt{65535} \\
      \StIntersect   & \texttt{65535} \\
    \end{tabular}
    \caption{size limits per state}
    \label{table:chain-sync-size-limits}
  \end{center}
\end{table}

\subsection{Node-to-node timeouts per state}
\label{subsec:chain-sync-timeouts}

The table~\ref{table:chain-sync-timeouts} specifies message timeouts in a given
state.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{timeout} \\\hline
      \StIdle        & \texttt{3673}s \\
      \StCanAwait    & \texttt{10}s   \\
      \StMustReply   & random between \texttt{135}s and \texttt{269}s \\
      \StIntersect   & \texttt{10}s   \\
    \end{tabular}
    \caption{timeouts per state}
    \label{table:chain-sync-timeouts}
  \end{center}
\end{table}

\subsection{Node-to-client size limits and timeouts}

There are no size-limits nor timeouts for the chain-sync mini-protocol of the
node-to-client protocol.


\newcommand{\readpointer}{\emph{read-pointer}}
\subsection{Implementation of the Chain Producer}
This section describes a stateful implementation of a chain producer that is suitable for a setting where
the producer cannot trust the chain consumer.
An important requirement in this setting
is that a chain consumer must never be able to cause excessive resource use on the producer side.
The presented implementation meets this requirement.
It uses a constant amount of memory to store the state that the producer maintains
per chain consumer.  This protocol is only used to reproduce the producer
chain locally by the consumer.  By running many instances of this protocol against
different peers, a node can reproduce chains in the network and
make chain selection, which by design is not part of this protocol.
Note that when we refer to the consumer's chain in this section, we mean
the chain that is reproduced by the consumer with the instance of
the chain-sync protocol and not the result of the chain selection algorithm.

We call the state which the producer maintains about the consumer the \readpointer{}.
The \readpointer{} basically tracks what the producer knows about the head of
the consumer's chain without storing it locally.
It points to a block on the current chain of the chain producer.
The \readpointer{}s are part of the shared state of the node (Figure~\ref{node-diagram-concurrency}), and
\readpointer{}s are concurrently updated by the thread that runs the chain-sync mini-protocol and the
chain tracking logic of the node itself.

We first describe how the mini-protocol updates a \readpointer{} and later address what happens in case
of a fork.
\subparagraph{Initializing the \readpointer{}.}
The chain producer assumes that a consumer which has just connected,
only knows the genesis block and initialises the \readpointer{} of that consumer
with a pointer to the genesis block on its chain.

\subparagraph{Downloading a chain of blocks}
A typical situation is when the consumer follows the chain of the producer but is not yet at the head of the
chain (this also covers a consumer booting from the genesis).
In this case, the protocol follows a simple, consumer-driven, request-response pattern.
The consumer sends \MsgRequestNext{} messages to ask for the next block.
If the \readpointer{} is not yet at the head of the chain,
the producer replies with a \MsgRollForward{} and advances the \readpointer{} to
the next block (optimistically assuming that the client will update its chain
accordingly).
The \MsgRollForward{} message contains the next block and also the head-point of the producer.
The protocol follows this pattern until the \readpointer{} reaches the end of its chain.

\begin{figure}[ht]
\pgfdeclareimage[height=7cm]{read-pointer-consumer-driver}{figure/read-pointer-consumer-driven.pdf}
\begin{center}
\pgfuseimage{read-pointer-consumer-driver}
\end{center}
\caption{Consumer-driven block download.}
\label{read-pointer-consumer-driver}
\end{figure}

\subparagraph{Producer driven updates}
If the \readpointer{} points to the end of the chain and the producer receives
a \MsgRequestNext{}
the consumer's chain is already up to date.
The producer informs the consumer with an \MsgAwaitReply{} that no new data is available.
After receiving a \MsgAwaitReply{}, the consumer waits for a new message, and the producer keeps agency.
The \MsgAwaitReply{} switches from a consumer-driven phase to a producer-driven phase.

The producer waits until new data becomes available.
When a new block is available, the producer will
send a \MsgRollForward{} message and give agency back to the consumer.
The producer can also get unblocked when its node switches to a new chain fork.

\subparagraph{Producer switches to a new fork}
The node of the chain producer can switch to a new fork at any time, independent of the
state machine.
A chain switch can cause an update of the \readpointer{},
which is part of the mutable state that is shared between the thread that runs
the chain sync protocol and the thread that implements the chain following the logic of the node.
There are two cases:

1) If the \readpointer{} points to a block that is on the common prefix of the new
fork and the old fork, no update of the \readpointer{} is needed.

2) If the \readpointer{} points to a block that is no longer part of the chain that is followed by the node,
the \readpointer{} is set to the last block that is common between the new and the old chain.
The node also sets a flag that signals the chain-sync thread to send a \MsgRollBackward{} instead
of a \MsgRollForward.
Finally, the producer thread must unblock if it is in the \StMustReply{} state.

\begin{figure}[ht]
\pgfdeclareimage[height=5cm]{read-pointer-rollback}{figure/read-pointer-rollback.pdf}
\begin{center}
\pgfuseimage{read-pointer-rollback}
\end{center}
\caption{\readpointer{} update for a fork switch in case of a rollback.}
\label{read-pointer-rollback}
\end{figure}

Figure~\ref{read-pointer-rollback} illustrates a fork switch that requires an update of the \readpointer{}
for one of the chain consumers.
Before the switch, the \readpointer{} of the consumer points to block $0x660f$.
The producer switches to a new chain with the head of the chain at block $0xcdf0$.
The node must update the \readpointer{} to block $0xfa40$, and the next message to the consumer
will be a \MsgRollBackward.

Note that a node typically communicates with several consumers. For each consumer, it runs an independent
version of the chain-sync-protocol state machine in an independent thread and with its own \readpointer{}.
Each of those \readpointer{}s has to be updated independently, and for each consumer,
either case 1) or case 2) can apply.

\subparagraph{Consumer starts with an arbitrary fork}
Typically, the consumer already knows some fork of the blockchain when it
starts to track the producer.
The protocol provides an efficient method to search for the longest common prefix (here called intersection)
between the fork of the producer and the fork that is known to the consumer.

To do so, the consumer sends a \MsgFindIntersect{} message with a list of chain
points on the chain known to the consumer.
If the producer does not know any of the points, it replies with \MsgIntersectNotFound.
Otherwise, it replies with \MsgIntersectFound{} and the best (i.e. the newest) of the points that it knows
and also updates the \readpointer{} accordingly.
For efficiency, the consumer should use a binary search scheme to search for the longest common
prefix.

It is advised that the consumer always starts with \MsgFindIntersect{} in a fresh connection
and it is free to use \MsgFindIntersect{} at any time later as it is beneficial.
If the consumer does not know anything about the producer's chain,
it can start the search with the following list of points:
$\langle point(b), point(b-1), point(b-2), point(b-4), point (b-8),\ldots \rangle$
where $point(b-i)$ is the point of the $i$th predecessor of block $b$ and
$b$ is the head of the consumer fork.
The maximum depth of a fork in Ouroboros is bounded, and the intersection will always be found with a small number of
iterations of this algorithm.

\subparagraph{Additional remarks}
Note that by sending \MsgFindIntersect{}, the server will not modify its
\readpointer{}.

\subsection{Implementation of the Chain Consumer}
In principle, the chain consumer has to guard against a malicious chain producer
as much as the other way around.
However, two aspects of the protocol play a role in favour of the consumer here.
\begin{itemize}
  \item The protocol is consumer-driven, i.e., the producer cannot send unsolicited
data to the consumer (within the protocol).
  \item The consumer can verify the response data itself.
\end{itemize}
Here are some cases to consider:
\begin{description}
\item[\MsgFindIntersect~Phase]
  The consumer and the producer play a number guessing game, so the consumer can easily detect
  inconsistent behaviour.
\item[The producer replies with a \MsgRollForward] The consumer can verify the block itself
  with the help of the ledger layer.
  (The consumer may need to download the block first if the protocol only sends block headers.)
\item[The producer replies with a \MsgRollBackward] The consumer tracks several producers, so
  if the producer sends false \MsgRollBackward{} messages, the consumer's node
  will, at some point, switch to a longer chain fork.
\item[The Producer is just passive/slow] The consumer's node will switch to
  a longer chain coming from another producer via another instance of
    chain-sync protocol.
\end{description}

\subsection{CDDL encoding specification}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/chain-sync.cddl}
See appendix \ref{cddl-common} for common definitions.

\section{Block-Fetch mini-protocol}
\label{block-fetch-protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.BlockFetch.Type}{ouroboros-network/protocols/Ouroboros-Network-Protocol-BlockFetch-Type.html\#t:BlockFetch}\\
\codechaddockref{Ouroboros.Network.Protocol.BlockFetch.Codec}{ouroboros-network/protocols/Ouroboros-Network-Protocol-BlockFetch-Codec.html\#v:codecBlockFetch}\\
\hyperref[table:node-to-node-protocol-numbers]{\textit{node-to-node mini-protocol number}}: \texttt{3}\\

\renewcommand{\StIdle}{\state{StIdle}}
\renewcommand{\StBusy}{\state{StBusy}}
\newcommand{\StStreaming}{\state{StStreaming}}
\renewcommand{\StDone}{\state{StDone}}
\newcommand{\MsgRequestRange}{\msg{MsgRequestRange}}
\newcommand{\MsgStartBatch}{\msg{MsgStartBatch}}
\newcommand{\MsgNoBlocks}{\msg{MsgNoBlocks}}
\newcommand{\MsgBlock}{\msg{MsgBlock}}
\newcommand{\MsgBatchDone}{\msg{MsgBatchDone}}
\newcommand{\MsgClientDone}{\msg{MsgClientDone}}

\subsection{Description}

The block fetching mechanism enables a node to download a range of blocks.

\subsection{State machine}

\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen,initial] at (-1cm,0cm)  (Idle)      {\StIdle};
    \node[state]                  at (4cm,0cm)   (Done)      {\StDone};
    \node[state, myblue]          at (-3cm,-3cm) (Busy)      {\StBusy};
    \node[state, myblue]          at (4cm,-3cm)  (Streaming) {\StStreaming};

    \draw (Idle)      edge[above]            node[fill=white]{\MsgClientDone}           (Done);
    \draw (Idle)      edge[left,bend right]  node[fill=white]{\MsgRequestRange}         (Busy);
    \draw (Busy)      edge[above,bend right] node[fill=white]{\MsgNoBlocks}             (Idle);
    \draw (Busy)      edge[below]            node[fill=white]{\MsgStartBatch}           (Streaming);
    \draw (Streaming) edge[loop right]       node[fill=white,left=-10mm]{\MsgBlock}     (Streaming);
    \draw (Streaming) edge[right]            node[fill=white,left=-15mm]{\MsgBatchDone} (Idle);
  \end{tikzpicture}
  \caption{State machine of the block-fetch mini-protocol}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StIdle        & \Client \\
      \StBusy        & \Server \\
      \StStreaming   & \Server \\
    \end{tabular}
    \caption{Block-Fetch state agencies}
  \end{center}
\end{figure}

\paragraph{Protocol messages}
\begin{description}
\item [\MsgRequestRange{} {\boldmath $(range)$}]
  The client requests a {\boldmath $range$} of blocks from the server.  The
  range is inclusive on both sides.
\item [\MsgNoBlocks]
  The server tells the client that it does not have all of the blocks in the requested {\boldmath $range$}.
\item [\MsgStartBatch]
  The server starts block streaming.
\item [\MsgBlock{} {\boldmath $(body)$}]
  Stream a single block's body.
\item [\MsgBatchDone]
  The server ends block streaming.
\item [\MsgClientDone]
  The client terminates the protocol.
\end{description}

The transitions are shown in table~\ref{table:block-fetch}.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|l|l|l}
      \header{from state} & \header{message} & \header{parameters} & \header{to state} \\\hline
      \StIdle       & \MsgClientDone   &            & \StDone      \\
      \StIdle       & \MsgRequestRange & $range$    & \StBusy      \\
      \StBusy       & \MsgNoBlocks     &            & \StIdle      \\
      \StBusy       & \MsgStartBatch   &            & \StStreaming \\
      \StStreaming  & \MsgBlock        & $body$     & \StStreaming \\
      \StStreaming  & \MsgBatchDone    &            & \StIdle      \\
    \end{tabular}
  \end{center}
  \caption{Block-Fetch mini-protocol messages.}
  \label{table:block-fetch}
\end{table}

\subsection{Size limits per state}

These bounds limit how many bytes can be sent in a given state; indirectly, this
limits the payload size of each message.  If a space limit is violated, the
connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StIdle        & \texttt{65535} \\
      \StBusy        & \texttt{65535} \\
      \StStreaming   & \texttt{2500000} \\
    \end{tabular}
    % \caption{size limits per state}
    \label{table:block-fetch-size-limits}
  \end{center}
\end{table}

\subsection{Timeouts per state}

These limits bound how much time the receiver side can wait for the arrival of
a message.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{timeout} \\\hline
      \StIdle        & - \\
      \StBusy        & \texttt{60}s \\
      \StStreaming   & \texttt{60}s \\
    \end{tabular}
    \caption{timeouts per state}
    \label{table:block-fetch-timeouts}
  \end{center}
\end{table}

\subsection{CDDL encoding specification}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/block-fetch.cddl}
See appendix \ref{cddl-common} for common definitions.

\section{Tx-Submission mini-protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.TxSubmission2.Type}{ouroboros-network/protocols/Ouroboros-Network-Protocol-TxSubmission2-Type.html\#t:TxSubmission2}\\
\codechaddockref{Ouroboros.Network.Protocol.TxSubmission2.Codec}{ouroboros-network/protocols/Ouroboros-Network-Protocol-TxSubmission2-Codec.html\#v:codecTxSubmission2}\\
\hyperref[table:node-to-node-protocol-numbers]{\textit{node-to-node mini-protocol number}}: \texttt{4}\\
\label{tx-submission-protocol}
\label{tx-submission-protocol2}

\newcommand{\StInit}             {\state{StInit}}
\newcommand{\MsgInit}            {\msg{MsgInit}}
\newcommand{\StTxIdsBlocking}    {\state{StTxIdsBlocking}}
\newcommand{\StTxIdsNonBlocking} {\state{StTxIdsNonBlocking}}
\newcommand{\StTxs}              {\state{StTxs}}
\newcommand{\MsgRequestTxIdsNB}  {\msg{MsgRequestTxIdsNonBlocking}}
\newcommand{\MsgRequestTxIdsB}   {\msg{MsgRequestTxIdsBlocking}}
\newcommand{\MsgReplyTxIds}      {\msg{MsgReplyTxIds}}
\newcommand{\MsgRequestTxs}      {\msg{MsgRequestTxs}}
\newcommand{\MsgReplyTxs}        {\msg{MsgReplyTxs}}

\subsubsection{Description}
The node-to-node transaction submission protocol is used to transfer
transactions between full nodes.  The protocol follows a pull-based strategy
where the initiator asks for new transactions, and the responder sends them
back.  It is suitable for a trustless setting where both sides need to guard
against resource consumption attacks from the other side.  The local
transaction submission protocol, is a simpler which is used when the server trusts a local
client, is described in Section \ref{local-tx-submission-protocol}.

The \textit{tx-submission} mini-protocol is designed in a way that the
information (e.g. transactions) flows across the system in the other direction
than in the \textit{chain-sync} or \textit{block-fetch} protocols.
Transactions must flow toward the block producer, while headers and blocks
disseminate from it to the rest of the system.  This is reflected in the
protocol graphs, transactions are sent from a client to
a server.  However, to preserve that all mini-protocols start on the client,
the \StInit{} state was added in version 2 of the protocol.

Note that Version 1 of the tx-submission protocol is no longer supported.
Version 2 is used since \texttt{NodeToNode\_V6} of the node-to-node protocol.
\subsection{State machine}

\begin{figure}[h!]
\begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
  \tikzstyle{every state}=[fill=red,draw=none,text=white]
  \node[state, mygreen, initial] (I) at (-4,  0) {\StInit};
  \node[state, myblue]           (A) at ( 0,  0) {\StIdle};
  \node[state]                   (B) at ( 9, -4) {\StDone};
  \node[state, mygreen]          (C) at ( 4, -4) {\StTxIdsBlocking};
  \node[state, mygreen]          (D) at (-4, -4) {\StTxIdsNonBlocking};
  \node[state, mygreen]          (E) at ( 0,  4) {\StTxs};
  \draw (I)  edge[above]                    node[above]{\MsgInit}                                                (A);
  \draw (C)  edge[above]                    node[below]{\MsgDone}                                                (B);
  \draw (A)  edge[left, bend left=45]       node[fill = white, anchor = center]{\MsgRequestTxIdsB}               (C);
  \draw (C)  edge[right, bend left=15]      node[fill = white, anchor = center, above = 2pt]{\MsgReplyTxIds}     (A);
  \draw (D)  edge[right, bend left=45]      node[fill = white, anchor = center]{\MsgReplyTxIds}                  (A);
  \draw (A)  edge[right, bend left=15]      node[fill = white, anchor = center, below = 2pt]{\MsgRequestTxIdsNB} (D);
  \draw (A)  edge[left, bend right=45]      node[fill = white, anchor = center, above = 2pt]{\MsgRequestTxs}     (E);
  \draw (E)  edge[right,bend right=45]      node[fill = white, anchor = center, below = 2pt]{\MsgReplyTxs}       (A);
\end{tikzpicture}
  \caption{State machine of the Tx-Submission mini-protocol (version 2).}
\label{tx-submission-automata-v2}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state}      & \header{agency} \\\hline
      \StInit             & \Client \\
      \StIdle             & \Server \\
      \StTxIdsBlocking    & \Client \\
      \StTxIdsNonBlocking & \Client \\
      \StTxs              & \Client \\
    \end{tabular}
    \caption{Tx-Submission state agencies}
  \end{center}
\end{figure}

\paragraph{Protocol messages}
\begin{description}
\item [\MsgInit] initial message of the protocol
\item [\MsgRequestTxIdsNB{} {\boldmath $(ack,req)$}]
      Request a non-empty list of transaction identifiers from the client,
      and confirm a number of outstanding transaction identifiers.

      This is a non-blocking operation: the response
      may be an empty list and this does expect a prompt response. This
      covers high throughput use cases where we wish to pipeline, by
      interleaving requests for additional transaction identifiers with
      requests for transactions, which requires these requests not block.

      The request gives the maximum number of transaction identifiers that
      can be accepted in the response. Either the numbers acknowledged or the
      number requested MUST be non-zero. In either case, the number requested
      MUST not put the total outstanding over the fixed protocol limit (see
      below in section~\ref{tx-submission-size-limits}).

      The request also gives the number of outstanding transaction identifiers
      that can now be acknowledged. The actual transactions to acknowledge are
      known to the peer based on the FIFO order in which they were provided.

      The request MUST be made (over \MsgRequestTxIdsB{}) if there are non-zer
      remaining unacknowledged transactions.
\item [\MsgRequestTxIdsB{} {\boldmath $(ack,req)$}]
      The server asks for new transaction ids and acknowledges old ids.
      The client will block until new transactions are available, thus the
      respond will always have at least one transaction identifier. 

      This is a blocking operation: the response will always have at least one
      transaction identifier, and it does not expect a prompt response: there
      is no timeout. This covers the case when there is nothing else to do but
      wait. For example this covers leaf nodes that rarely, if ever, create and
      submit a transaction.

      The request gives the maximum number of transaction identifiers that
      can be accepted in the response. This must be greater than zero.
      The number requested ids MUST not put the total outstanding over
      the fixed protocol limit (see below in
      section~\ref{tx-submission-size-limits}).

      The request also gives the number of outstanding transaction identifiers
      that can now be acknowledged. The actual transactions to acknowledge are
      known to the peer based on the FIFO order in which they were provided.

      The request MUST be made (over \MsgRequestTxIdsNB{}) if there are zero
      remaining unacknowledged transactions.
\item [\MsgReplyTxIds{} {\boldmath ($\langle (id, size) \rangle$) }]
      The client replies with a list of available transactions.
      The list contains pairs of transaction ids and the corresponding size of the transaction in bytes.
      In the blocking case, the reply MUST contain at least one transaction identifier.
      In the non-blocking case, the reply may contain an empty list.

      These transactions are added to the notional FIFO of outstanding
      transaction identifiers for the protocol.

      The order in which these transaction identifiers are returned must be the
      order in which they are submitted to the mempool, to preserve dependent
      transactions.
\item [\MsgRequestTxs{} {\boldmath ($\langle ids \rangle$)}]
      The server requests transactions by sending a non-empty list of transaction-ids.

      While it is the responsibility of the replying peer to keep within
      pipelining in-flight limits, the sender must also cooperate by keeping
      the total requested across all in-flight requests within the limits.

      It is an error to ask for transaction identifiers that were not
      previously announced (via \MsgReplyTxIds{}).

      It is an error to ask for transaction identifiers that are not
      outstanding or that were already asked for.
\item [\MsgReplyTxs{} {\boldmath ($\langle txs \rangle$})]
      The client replies with a list of transactions.  It may implicitly
      discard transaction-ids which were requested.

      Transactions can become invalid between the time the transaction
      identifier was sent and the transaction being requested. Invalid
      (including committed) transactions do not need to be sent.

      Any transaction identifiers requested but not provided in this reply
      should be considered as if this peer had never announced them. (Note
      that this is no guarantee that the transaction is invalid, it may still
      be valid and available from another peer).
\item [\MsgDone]
      Termination message, initiated by the client when the server is making
      a blocking call for more transaction identifiers.
\end{description}

\begin{table}[h!]
  \begin{tabular}{l|l|l|l}
    \header{from state} & \header{message}    & \header{parameters}           & \header{to state}   \\\hline
    \StInit             & \MsgInit            &                               & \StIdle             \\
    \StIdle             & \MsgRequestTxIdsNB  & $ack$,$req$                   & \StTxIdsNonBlocking \\
    \StIdle             & \MsgRequestTxIdsB   & $ack$,$req$                   & \StTxIdsBlocking    \\
    \StTxIdsNonBlocking & \MsgReplyTxIds      & $\langle (id, size) \rangle$  & \StIdle             \\
    \StTxIdsBlocking    & \MsgReplyTxIds      & $\langle (id, size) \rangle$  & \StIdle             \\
    \StIdle             & \MsgRequestTxs      & $\langle ids \rangle$         & \StTxs              \\
    \StTxs              & \MsgReplyTxs        & $\langle txs \rangle$         & \StIdle             \\
    \StTxIdsBlocking    & \MsgDone            &                               & \StDone             \\
  \end{tabular}
  \caption{Tx-Submission mini-protocol (version 2) messages.}
\end{table}

\subsection{Size limits per state}
\label{tx-submission-size-limits}

Table~\ref{table:tx-submission-size-limits} specifies how many bytes can be sent
in a given state; indirectly, this limits the payload size of each message.  If
a space limit is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state}      & \header{size limit in bytes} \\\hline
      \StInit             & \texttt{5760} \\
      \StIdle             & \texttt{5760} \\
      \StTxIdsBlocking    & \texttt{2500000} \\
      \StTxIdsNonBlocking & \texttt{2500000} \\
      \StTxs              & \texttt{2500000} \\
    \end{tabular}
    \caption{size limits per state}
    \label{table:tx-submission-size-limits}
  \end{center}
\end{table}

\subsubsection{Maximum number of unacknowledged transaction identifiers}

The maximal number of unacknowledged transactions ids is \texttt{10}.  It is
a protocol error to exceed it.

\subsection{Timeouts per state}

The table~\ref{table:tx-submission-timeouts} specifies message timeouts in
a given state.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state}      & \header{timeout} \\\hline
      \StInit             & - \\
      \StIdle             & - \\
      \StTxIdsBlocking    & - \\
      \StTxIdsNonBlocking & \texttt{10}s \\
      \StTxs              & \texttt{10}s \\
    \end{tabular}
    \caption{timeouts per state}
    \label{table:tx-submission-timeouts}
  \end{center}
\end{table}

\subsection{CDDL encoding specification}\label{tx-submission2-cddl}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/tx-submission2.cddl}

\subsection{Client and Server Implementation}
The protocol has two design goals: It must diffuse transactions with high efficiency
and, at the same time, it must rule out
asymmetric resource attacks from the transaction consumer against the transaction provider.

The protocol is based on two pull-based operations.
The transaction consumer can ask for a number of transaction ids, and it can use these
transaction ids to request a batch of transactions.
The transaction consumer has flexibility in the number of transaction ids it requests,
whether to actually download the transaction body
and flexibility in how it batches the download of transactions.
The transaction consumer can also switch between requesting transaction ids and downloading
transaction bodies at any time.
It must, however, observe several constraints that are necessary for a memory-efficient implementation
of the transaction provider.

Conceptually, the provider maintains a limited size FIFO of outstanding transactions per consumer.
(The actual implementation can, of course, use the data structure that works best).
The maximum FIFO size is a protocol parameter.
The protocol guarantees that, at any time, the consumer and producer agree on the current size of
that FIFO and on the outstanding transaction ids.
The consumer can use a variety of heuristics to request transaction ids and transactions.
One possible implementation for a consumer is to maintain a FIFO that mirrors the producer's FIFO
but only contains the transaction ids (and the size of the transaction) and not the full transactions.

After the consumer requests new transaction ids, the provider replies with a list of transaction ids and
puts these transactions in its FIFO.
As part of a request, a consumer also acknowledges the number of old transactions,
which are removed from the FIFO at the same time.
The provider checks that the size of the FIFO, i.e. the number of outstanding transactions,
never exceeds the protocol limit and aborts the connection if a request violates the limits.
The consumer can request any batch of transactions from the current FIFO in any order.
Note, however, that the reply will omit any transactions that have become invalid in the meantime.
(More precisely, the server will omit invalid transactions from the reply, but they will still be counted in the FIFO
size, and they will still require an acknowledgement from the consumer).

The protocol supports blocking and non-blocking requests for new transactions ids.
If the FIFO is empty, the consumer must use a blocking request; otherwise, it must be a non-blocking request.
The producer must reply immediately (i.e. within a small timeout) to a non-blocking request.
It replies with not more than the requested number of ids (possibly with an empty list).
A blocking request, on the other side, waits until at least one transaction is available.

\section{Keep Alive Mini Protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.KeepAlive.Type}{ouroboros-network/protocols/Ouroboros-Network-Protocol-KeepAlive-Type.html\#t:KeepAlive}\\
\codechaddockref{Ouroboros.Network.Protocol.KeepAlive.Codec}{ouroboros-network/protocols/Ouroboros-Network-Protocol-KeepAlive-Codec.html\#v:codecKeepAlive\_v2}\\
\hyperref[table:node-to-node-protocol-numbers]{\textit{node-to-node mini-protocol number}}: \texttt{8}\\

\label{keep-alive-protocol}
\subsection{Description}
Keep-alive mini-protocol is a member of the node-to-node protocol.  It is used for
two purposes: to provide keep alive messages and do round trip time
measurements.

\newcommand{\StClient}{\state{StClient}}
\newcommand{\StServer}{\state{StServer}}
\newcommand{\MsgKeepAlive}{\trans{MsgKeepAlive}}
\newcommand{\MsgKeepAliveResponse}{\trans{MsgKeepAliveResponse}}
\subsection{State machine}

\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]        (Client)  {\StClient};
    \node[state, myblue, right of=Client] (Server)  {\StServer};
    \node[state, below of=Client]         (Done)    {\StDone};

    \draw (Client) edge[above, bend left=45] node{\MsgKeepAlive}         (Server);
    \draw (Server) edge[below, bend left=45] node{\MsgKeepAliveResponse} (Client);
    \draw (Client) edge[left]                node{\MsgDone}              (Done);
  \end{tikzpicture}
  \caption{State machine of the keep-alive protocol.}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StClient      & \Client \\
      \StServer      & \Server \\
    \end{tabular}
    \caption{Keep-Alive state agencies}
  \end{center}
\end{figure}

\paragraph{Protocol messages}
\begin{description}
\item [\MsgKeepAlive{} $cookie$]
  Keep alive message.  The $cookie$ value is a \texttt{Word16} value, which allows to
  match requests with responses.  It is a protocol error if the cookie received
  back with \MsgKeepAliveResponse{} does not match the value sent with
  \MsgKeepAlive{}.
\item [\MsgKeepAliveResponse{} $cookie$]
  Keep alive response message.
\item [\MsgDone]
  Terminating message.
\end{description}

\subsection{Size limits per state}

These bounds limit how many bytes can be sent in a given state; indirectly, this
limits the payload size of each message.  If a space limit is violated, the
connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StClient      & \texttt{65535} \\
      \StServer      & \texttt{65535} \\
    \end{tabular}
    % \caption{size limits per state}
    \label{table:keep-alive-size-limits}
  \end{center}
\end{table}

\subsection{Timeouts per state}

These limits bound how much time the receiver side can wait for the arrival of
a message.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{timeout} \\\hline
      \StClient      & \texttt{97}s \\
      \StServer      & \texttt{60}s \\
    \end{tabular}
    \caption{timeouts per state}
    \label{table:keep-alive-timeouts}
  \end{center}
\end{table}

\subsection{CDDL encoding specification}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/keep-alive.cddl}

\section{Peer Sharing mini-protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.PeerSharing.Type}{ouroboros-network/protocols/Ouroboros-Network-Protocol-PeerSharing-Type.html\#t:PeerSharing}\\
\codechaddockref{Ouroboros.Network.Protocol.PeerSharing.Codec}{ouroboros-network/protocols/Ouroboros-Network-Protocol-PeerSharing-Codec.html\#v:codecPeerSharing}\\
\hyperref[table:node-to-node-protocol-numbers]{\textit{node-to-node mini-protocol number}}: \texttt{10}\\
\label{peer-sharing-protocol}
\subsection{Description}
The Peer-Sharing mini-protocol is a simple Request-Reply mini-protocol. The mini-protocol is used by nodes to share their upstream peers (a subset of their Known Peers).

\newcommand{\PsClient}{\state{StIdle}}
\newcommand{\PsServer}{\state{StBusy}}
\newcommand{\MsgShareRequest}{\trans{MsgShareRequest}}
\newcommand{\MsgSharePeers}{\trans{MsgSharePeers}}
\subsection{State machine}

\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4.5cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]        (Idle)  {\StIdle};
    \node[state, myblue, right of=Client] (Busy)  {\StBusy};
    \node[state, below of=Client]         (Done)  {\StDone};

    \draw (Idle) edge[above, bend left=45] node{\MsgShareRequest} (Busy);
    \draw (Busy) edge[below, bend left=45] node{\MsgSharePeers}   (Idle);
    \draw (Idle) edge[left]                node{\MsgDone}         (Done);
  \end{tikzpicture}
  \caption{State machine of the peer sharing protocol.}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StIdle        & \Client \\
      \StBusy        & \Server \\
    \end{tabular}
    \caption{Peer-Sharing state agencies}
  \end{center}
\end{figure}

\paragraph{Protocol messages}
\begin{description}
\item [\MsgShareRequest{} $amount$]
  The client requests a maximum number of peers to be shared ($amount$). Ideally, this
  amount should limited by a protocol level constant to disallow a bad actor from
  requesting too many peers.
\item [\MsgSharePeers{} ${[}peerAddress{]}$]
  The server replies with a set of peers. The amount of information send is
    limited by message size limit (see below).

  It is a protocol error to send more peers than it was requested.

  The server should only share peers with which it has (or recently had) an
  successful inbound or outbound session.
\item [\MsgDone]
  Terminating message.
\end{description}

\subsection{Size limits per state}

These bounds limit how many bytes can be sent in a given state; indirectly, this
limits the payload size of each message.  If a space limit is violated, the
connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{size limit in bytes} \\\hline
      \StIdle        & \texttt{5760} \\
      \StBusy        & \texttt{5760} \\
    \end{tabular}
    % \caption{size limits per state}
    \label{table:peer-share-size-limits}
  \end{center}
\end{table}

\subsection{Timeouts per state}

These limits bound how much time the receiver side can wait for the arrival of
a message.  If a timeout is violated, the connection SHOULD be torn down.

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|r}
      \header{state} & \header{timeout} \\\hline
      \StIdle        & - \\
      \StBusy        & \texttt{60}s \\
    \end{tabular}
    \caption{timeouts per state}
    \label{table:peer-share-timeouts}
  \end{center}
\end{table}

\subsection{Client Implementation Details}

The initiator side will have to be running indefinitely since protocol termination means
either an error or peer demotion. Because of this, the protocol won't be able to be run as
a simple request-response protocol. To overcome this, the client-side implementation will
use a registry so that each connected peer gets registered and assigned a controller with
a request mailbox. This controller will be used to issue requests to the client
implementation, which will be waiting for the queue to be filled up to send a
\MsgShareRequest. After sending a request, the result is put into a local result mailbox.

If a peer gets disconnected, it should get unregistered.

\subsubsection{Deciding from whom to request peers (and how many)}

First of all, peer-sharing requests should only be issued if:

\begin{itemize}
  \item The current number of known peers is less than the target for known peers;
  \item The rate limit value for peer sharing requests isn't exceeded;
  \item There are available peers to issue requests to;
\end{itemize}

If these conditions hold, then we can pick a set of peers to issue requests to.
Ideally, this set respects the rate limit value for peer-sharing requests.

If a peer has \texttt{PeerSharingDisabled}, flag value, do not ask it for peers.
This peer won't even have the Peer-Sharing miniprotocol server running.

The number of peers to request from each upstream peer should aim to fulfil
the target for known peers. This number should be split for the current peer
target objective across all peer-sharing candidates for efficiency and
diversity reasons.

\subsubsection{Picking peers for the response}

Apart from managing the Outbound Governor state correctly, the final result
set should be a random distribution of the original set.

This selection should be done in such a way that when the same initial PRNG
state is used, the selected set does not significantly vary with small
perturbations in the set of published peers.

The intention of this selection method is that the selection should give
approximately the same replies to the same peers over the course of multiple
requests from the same peer. This is to deliberately slow the rate at which
peers can discover and map out the entire network.

\subsection{Server Implementation Details}

As soon as the server receives a share request, it needs to pick a subset not bigger than the
value specified in the request's parameter. The reply set needs to be sampled randomly
from the Known Peer set according to the following constraints:

\begin{itemize}
  \item Only pick peers that we managed to connect to at some point
  \item Don't pick known-to-be-ledger peers
  \item Pick peers that have public willingness information (e.g. \texttt{DoAdvertisePeer}).
  \item Pick peers that haven't behaved badly (e.g. \texttt{PeerFailCount == 0})
\end{itemize}

Computing the result (i.e. random sampling of available peers) needs access to the
\texttt{PeerSelectionState}, which is specific to the \texttt{peerSelectionGovernorLoop}. However, when
initialising the server side of the mini-protocol, we have to provide the result computing
function early on the consensus side. This means we will have to find a way to delay the
function application all the way to diffusion and share the relevant parts of
\texttt{PeerSelectionState} with this function via a \texttt{TVar}.

\subsection{CDDL encoding specification ($\geq 14$)}\label{peersharing-cddl}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/peer-sharing-v14.cddl}

\section{Local Tx-Submission mini-protocol}
\protocolhaddockref{Ouroboros.Network.Protocol.LocalTxSubmission.Type}{ouroboros-network/protocols/Ouroboros-Network-Protocol-LocalTxSubmission-Type.html\#t:LocalTxSubmission}\\
\codechaddockref{Ouroboros.Network.Protocol.LocalTxSubmission.Codec}{ouroboros-network/protocols/Ouroboros-Network-Protocol-LocalTxSubmission-Codec.html\#v:codecLocalTxSubmission}\\
\hyperref[table:node-to-client-protocol-numbers]{\textit{node-to-client mini-protocol number}}: \texttt{6}\\
\label{local-tx-submission-protocol}
\subsection{Description}
The local transaction submission mini protocol is used by local clients,
For example, wallets or CLI tools are used to submit transactions to a local node.
The protocol is {\bf not} used to forward transactions from one core node to another.
The protocol for the transfer of transactions between full nodes
is described in Section \ref{tx-submission-protocol2}.

The protocol follows a simple request-response pattern:
\begin{enumerate}
\item The client sends a request with a single transaction.
\item The Server either accepts the transaction (returning a confirmation) or rejects it (returning the
  reason).
\end{enumerate}
Note that the local transaction submission protocol is a push-based protocol where the client
creates a workload for the server.
This is acceptable because this mini-protocol is only to be used between a node and a local client.
\newcommand{\MsgSubmitTx}{\msg{MsgSubmitTx}}
\newcommand{\MsgAcceptTx}{\msg{MsgAcceptTx}}
\newcommand{\MsgRejectTx}{\msg{MsgRejectTx}}

\subsection{State machine}
\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]      (Idle) {\StIdle};
    \node[state, right of=Idle]         (Done) {\StDone};
    \node[state, myblue, above of=Idle] (Busy) {\StBusy};

    \draw (Idle)     edge[]                           node{\MsgDone}                                        (Done);
    \draw (Idle.0)   to[out=30,  in=330]              node[fill=white, left=-2mm]{\MsgSubmitTx}             (Busy.0);
    \draw (Busy.185) to[out=180, in=180, looseness=2] node[fill=white, right=10mm, below=3mm]{\MsgAcceptTx} (Idle.175);
    \draw (Busy.190) to[out=240, in=120]              node[fill=white, left=10mm, above=3mm]{\MsgRejectTx}  (Idle.170);
  \end{tikzpicture}
\caption{State machine of the Local Tx-Submission mini-protocol.}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StIdle        & \Client \\
      \StBusy        & \Server \\
    \end{tabular}
    \caption{Local Tx-Submission state agencies}
  \end{center}
\end{figure}


\paragraph{Protocol messages}
\begin{description}
\item [\MsgSubmitTx{} {\boldmath $(t)$}]
      The client submits a single transaction.  It MUST wait for a reply.
\item [\MsgAcceptTx]
      The server confirms that it accepted the transaction.
\item [\MsgRejectTx{} {\boldmath $(reason)$}]
      The server informs the client that it rejected the transaction and provides a $reason$.
\item [\MsgDone]
      The client terminates the mini protocol.
\end{description}

\subsection{Size limits per state}

No size limits.

\subsection{Timeouts per state}

No timeouts.

\subsection{CDDL encoding specification}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/local-tx-submission.cddl}
See appendix \ref{cddl-common} for common definitions.

\section{Local State Query mini-protocol}
\label{local-state-query-protocol}
\protocolhaddockref{Cardano.Network.Protocol.LocalStateQuery.Type}{cardano-diffusion/protocols/Cardano-Network-Protocol-LocalStateQuery-Type.html\#t:LocalStateQuery}\\
\codechaddockref{Cardano.Network.Protocol.LocalStateQuery.Codec}{cardano-diffusion/protocols/Cardano-Network-Protocol-LocalStateQuery-Codec.html\#v:codecLocalStateQuery}\\
\hyperref[table:node-to-client-protocol-numbers]{\textit{node-to-client mini-protocol number}}: \texttt{7}\\
\newcommand{\StAcquiring}{\state{Acquiring}}
\newcommand{\StAcquired}{\state{Acquired}}
\newcommand{\StQuerying}{\state{Querying}}
\newcommand{\MsgAcquire}{\msg{MsgAcquire}}
\newcommand{\MsgAcquired}{\msg{MsgAcquired}}
\newcommand{\MsgFailure}{\msg{MsgFailure}}
\newcommand{\MsgQuery}{\msg{MsgQuery}}
\newcommand{\MsgResult}{\msg{MsgResult}}
\newcommand{\MsgRelease}{\msg{MsgRelease}}
\newcommand{\MsgReAcquire}{\msg{MsgReAcquire}}

\subsection{Description}
Local State Query mini-protocol allows querying of the consensus/ledger state.
This mini protocol is part of the node-to-client protocol; hence, it is only
used by local (and thus trusted) clients.  Possible queries depend on the era
(Byron, Shelly, etc.) and are not specified in this document.  The protocol
specifies basic operations like acquiring/releasing the consensus/ledger
state, which is done by the server, or running queries against the acquired
ledger state.

\subsection{State machine}
\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4cm,semithick]
    \tikzstyle{every state}=[fill=red,draw,none,text=white]
    \node[state, mygreen, initial] (Idle) {\StIdle};
    \node[state, myblue, right of=Idle] (Acquiring) {\StAcquiring};
    \node[state, mygreen, right of=Acquiring] (Acquired) {\StAcquired};
    \node[state, myblue, right of=Acquired] (Querying) {\StQuerying};
    \node[state,         below of=Idle] (Done) {\StDone};

    \draw (Idle)      edge[bend left=45] node{\MsgAcquire}   (Acquiring);
    \draw (Acquiring) edge[bend left=45] node{\MsgFailure}   (Idle);
    \draw (Acquiring) edge[bend left=45] node{\MsgAcquired}  (Acquired);
    \draw (Acquired)  edge[bend left=45] node{\MsgReAcquire} (Acquiring);
    \draw (Acquired)  edge[bend left=45] node{\MsgQuery}     (Querying);
    \draw (Acquired.275)
                      to[in=-65, out=-115] node{\MsgRelease} (Idle.260);
    \draw (Querying)  edge[bend left=45] node{\MsgResult}    (Acquired);
    \draw (Idle)      edge node[left]{\MsgDone}              (Done);
  \end{tikzpicture}
  \caption{State machine of the Local State Query mini-protocol.}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StIdle        & \Client \\
      \StAcquiring   & \Server \\
      \StAcquired    & \Client \\
      \StQuerying    & \Server \\
    \end{tabular}
  \end{center}
\end{figure}


\paragraph{Protocol messages}

See Figure~\ref{fig:lsq-messages}, where $AcquireFailure$ is either:
\begin{itemize}
  \item $AcquireFailurePointTooOld$, or
  \item $AcquireFailurePointNotOnChain$
\end{itemize}
$Target$ is either $ImmutableTip$, $VolatileTip$, or $SpecificPoint pt$.

The primary motivation for being able to acquire the $ImmutableTip$ is that
it's the most recent ledger state that the node will never abandon: the node
will never rollback to a prefix of that immutable chain (unless the on-disk
ChainDB is corrupted/manipulated). Therefore, answers to queries against the
$ImmutableTip$ is necessarily not subject to rollback.

\begin{description}
  \item [\MsgAcquire{}]
    The client requests that the $Target$ ledger state on the server's be made
    available to query, and waits for confirmation or failure.
  \item [\MsgAcquired{}]
    The server can confirm that it has the state at the requested point.
  \item [\MsgFailure{}]
    The server can report that it cannot obtain the state for the requested
    point.
  \item [\MsgQuery{}]
    The client can perform queries on the current acquired state.
  \item [\MsgResult{}]
    The server must reply with the queries.
  \item [\MsgRelease{}]
    The client can instruct the server to release the state. This lets the
    server free resources.
  \item [\MsgReAcquire{}]
    This is like \MsgAcquire{} but for when the client already has a state. By
    moving to another state directly without a \MsgRelease{} it
    enables optimisations on the server side (e.g. moving to the state for
    the immediate next block).

    Note that failure to re-acquire is equivalent to \MsgRelease{},
    rather than keeping the exiting acquired state.
  \item [\MsgDone{}]
    The client can terminate the protocol.
\end{description}

% TODO natural language description of each message

\begin{figure}[h]
  \begin{tabular}{l|l|l|l}
    \header{from state} & \header{message}    & \header{parameters} & \header{to state} \\ \hline
    \StIdle             & \MsgAcquire         & $Target\ point$     & \StAcquiring \\
    \StAcquiring        & \MsgFailure         & $AcquireFailure$    & \StIdle      \\
    \StAcquiring        & \MsgAcquired        &                     & \StAcquired  \\
    \StAcquired         & \MsgQuery           & $query$             & \StQuerying  \\
    \StQuerying         & \MsgResult          & $result$            & \StAcquired  \\
    \StAcquired         & \MsgReAcquire       & $Target\ point$     & \StAcquiring \\
    \StAcquired         & \MsgRelease         &                     & \StIdle      \\
    \StIdle             & \MsgDone            &                     & \StDone      \\
  \end{tabular}
  \caption{Local State Query mini-protocol messages.}
  \label{fig:lsq-messages}
\end{figure}

\subsection{Size limits per state}

No size limits.

\subsection{Timeouts per state}

No timeouts.

\subsection{CDDL encoding specification}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/local-state-query.cddl}
See appendix \ref{cddl-common} for common definitions.

\section{Local Tx-Monitor mini-protocol}
\protocolhaddockref{Cardano.Network.Protocol.LocalTxMonitor.Type}{cardano-diffusion/protocols/Cardano-Network-Protocol-LocalTxMonitor-Type.html\#t:LocalTxMonitor}\\
\codechaddockref{Cardano.Network.Protocol.LocalTxMonitor.Codec}{cardano-diffusion/protocols/Cardano-Network-Protocol-LocalTxMonitor-Codec.html\#v:codecLocalTxMonitor}\\
\hyperref[table:node-to-client-protocol-numbers]{\textit{node-to-client mini-protocol number}}: \texttt{9}\\
\label{local-tx-monitor-protocol}
\newcommand{\MsgAwaitAcquire}{\msg{MsgAwaitAcquire}}

\newcommand{\NextTx}{\state{NextTx}}
\newcommand{\MsgNextTx}{\msg{MsgNextTx}}
\newcommand{\MsgReplyNextTx}{\msg{MsgReplyNextTx}}

\newcommand{\MsgHasTx}{\msg{MsgHasTx}}
\newcommand{\HasTx}{\state{HasTx}}
\newcommand{\MsgReplyHasTx}{\msg{MsgReplyHasTx}}

\newcommand{\GetSizes}{\state{GetSizes}}
\newcommand{\MsgGetSizes}{\msg{MsgGetSizes}}
\newcommand{\MsgReplyGetSizes}{\msg{MsgReplyGetSizes}}

\newcommand{\GetMeasures}{\state{GetMeasures}}
\newcommand{\MsgGetMeasures}{\msg{MsgGetMeasures}}
\newcommand{\MsgReplyGetMeasures}{\msg{MsgReplyGetMeasures}}

\subsection{Description}

A mini-protocol which allows the monitoring of transactions in the local mempool. This
mini-protocol is stateful; the server side tracks transactions already sent to
the client.

\subsection{State machine}

\begin{figure}[h]
  \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=4cm, semithick]
    \tikzstyle{every state}=[fill=red,draw=none,text=white]
    \node[state, mygreen, initial]                                   (Idle)            {\StIdle};
    \node[state, myblue, right of=Idle]                              (Acquiring)       {\StAcquiring};
    \node[state, mygreen, right of=Acquiring]                        (Acquired)        {\StAcquired};
    \node[state, myblue, right of=Acquired]                          (BusyHasTx)       {\StBusy\ \HasTx};
    \node[state, myblue, above of=BusyHasTx]                         (BusyNextTx)      {\StBusy\ \NextTx};
    \node[state, myblue, below of=BusyHasTx]                         (BusyGetSizes)    {\StBusy\ \GetSizes};
    \node[state, myblue, below of=Acquired]                          (BusyGetMeasures) {\StBusy\ \GetMeasures};
    \node[state, below of=Idle]                                      (Done)            {\StDone};

    \draw (Idle)            edge               node{\MsgAcquire}                   (Acquiring);
    \draw (Acquiring)       edge[bend left=45] node{\MsgAcquired}                  (Acquired);
    \draw (Acquired)        edge[bend left=45] node{\MsgRelease}                   (Idle);
    \draw (Acquired)        edge[bend left=45] node[fill=white]{\MsgAwaitAcquire}  (Acquiring);
    \draw (Acquired)        edge[bend left=20] node[left=-20pt,fill=white]{\MsgNextTx}
                                                                                   (BusyNextTx);
    \draw (BusyNextTx)      edge[bend left=20] node[right=-20pt,fill=white]{\MsgReplyNextTx}
                                                                                   (Acquired);
    \draw (Acquired)        edge[bend left=20] node[right=-20pt,fill=white]{\MsgGetSizes}
                                               (BusyGetSizes);
    \draw (BusyGetSizes)    edge[bend left=20] node[right=-20pt,pos=0.56,fill=white]{\MsgReplyGetSizes}
                                               (Acquired);
    \draw (Acquired)        edge[bend left=20] node[pos=0.7,right=-20pt,fill=white]{\MsgGetMeasures}
                                               (BusyGetMeasures);
    \draw (BusyGetMeasures) edge[bend left=20] node[pos=0.20,left=-15pt,fill=white]{\MsgReplyGetMeasures}
                                               (Acquired);
    \draw (Acquired)        edge[bend left=20] node[fill=white]{\MsgHasTx}         (BusyHasTx);
    \draw (BusyHasTx)       edge[bend left=20] node[fill=white,pos=0.45]{\MsgReplyHasTx}    (Acquired);
    \draw (Idle)            edge               node{\MsgDone}                      (Done);
  \end{tikzpicture}
  \caption{State machine of the Local Tx-Monitor mini-protocol.}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{state} & \header{agency} \\\hline
      \StIdle        & \Client \\
      \StAcquiring   & \Server \\
      \StAcquired    & \Client \\
      \StBusy        & \Server \\
    \end{tabular}
    \caption{Local Tx-Monitor state agencies}
  \end{center}
\end{figure}

\paragraph{Protocol messages}
\begin{description}
  \item[\MsgAcquire{}] Acquire the latest snapshot. This enables subsequent
    queries to be made against a consistent view of the mempool.
  \item[\MsgAcquired{} {\boldmath (SlotNo)}] The server side is now locked to
    a particular mempool snapshot. It returns the slot number of the 'virtual
    block' under construction.
  \item[\MsgAwaitAcquire{}] Like 'MsgAcquire' but await a new snapshot
    different from the one currently acquired.
  \item[\MsgRelease{}] Release the acquired snapshot in order to loop back to
    the idle state.
  \item[\MsgNextTx{}] The client requests a single transaction and waits for
    a reply.
  \item[\MsgReplyNextTx{} \boldmath(\textbf{Nothing} | \textbf{Just} $tx$)] The
    server responds with a single transaction if one is available in the
    mempool. This must be a transaction that was not previously sent to the
    client for this particular snapshot.
  \item[\MsgHasTx{}] The client checks whether the server knows of a particular
    transaction identified by its id.
  \item[\MsgReplyHasTx{} (Bool)] The server responds \texttt{True} when the given tx
    is present in the snapshot, \texttt{False} otherwise.
  \item[\MsgGetSizes{}] The client asks the server about the mempool current
    size and max capacity.
  \item[\MsgReplyGetSizes{} (Word32,Word32,Word32)] The server responds with
    three sizes.  The meaning of them are:
    \begin{description}
      \item[capacity in bytes] the maximum capacity of the mempool {\small (note that
        this may dynamically change when the ledger state is updated)};
      \item[size in bytes] the summed byte size of all the transactions in the
        mempool;
      \item[number of transactions] the number of transactions in the mempool.
    \end{description}
  \item[\MsgGetMeasures{}] The client asks the server for information on the mempool's measures.
  \item[\MsgReplyGetMeasures{} (Word32, Map Text (Integer, Integer))] The server responds with
    the total number of transactions currently in the mempool, and a map of the measures known to
    the mempool. The keys of this map are textual labels of the measure names, which should
    typically be considered stable for a given node version, and the values are a pair of integers
    representing the current size and maximum capacity respectively for that measure. The maximum
    capacity should not be considered fixed and is likely to change due to mempool conditions. The
    size should always be less than or equal to the capacity.
\end{description}

\begin{figure}[h]
  \begin{tabular}{l|l|l|l}
    \header{from state}    & \header{message}      & \header{parameters}                      & \header{to state} \\ \hline
    \StIdle                & \MsgAcquire           &                                          & \StAcquiring \\
    \StAcquiring           & \MsgAcquired          & SlotNo                                   & \StAcquired \\
    \StAcquired            & \MsgAwaitAcquire      &                                          & \StAcquiring \\
    \StAcquired            & \MsgRelease           &                                          & \StIdle \\
    \StAcquired            & \MsgNextTx            &                                          & \StBusy\ \NextTx\\
    \StBusy\ \NextTx       & \MsgReplyNextTx       & (\textbf{Nothing} | \textbf{Just} $tx$)  & \StAcquired\\
    \StAcquired            & \MsgHasTx             &                                          & \StBusy\ \HasTx\\
    \StBusy\ \HasTx        & \MsgReplyNextTx       & Bool                                     & \StAcquired\\
    \StAcquired            & \MsgGetSizes          &                                          & \StBusy\ \GetSizes\\
    \StBusy\ \GetSizes     & \MsgReplyGetSizes     & Word32,Word32,Word32                     & \StAcquired\\
    \StAcquired            & \MsgGetMeasures       &                                          & \StBusy\ \GetMeasures\\
    \StBusy\ \GetMeasures  & \MsgReplyGetMeasures  & Word32,Map Text (Integer,Integer)        & \StAcquired\\
    \StIdle                & \MsgDone              &                                          & \StDone\\
  \end{tabular}
  \caption{Local Transaction Monitor mini-protocol messages.}
  \label{fig:ltxm-messages}
\end{figure}

\subsection{Size limits per state}

No size limits.

\subsection{Timeouts per state}

No timeouts.

\subsection{CDDL encoding specification}
\lstinputlisting[style=cddl]{../../cardano-diffusion/protocols/cddl/specs/local-tx-monitor.cddl}
See appendix \ref{cddl-common} for common definitions.

\section{Pipelining of Mini Protocols}
\label{pipelining}
Protocol pipelining is a technique that improves the performance of some protocols.
The underlying idea is that a client that wants to perform several requests
just transmits those requests in sequence without blocking and waiting for the reply from the server.
In the reference implementation, pipelining is used by the clients of all mini-protocols except Chain-Sync.
Those mini-protocols follow a request-response pattern that is amenable to pipelining such
that pipelining becomes a feature of the client implementation and does not require any
modifications to the server implementation.

As an example, let's consider the Block-Fetch mini protocol.
When a client follows the protocol and sends a sequence of \MsgRequestRange{}~messages to the server, the data stream from the client to the server will only consist of \MsgRequestRange~messages
(and a final \MsgClientDone~message) and no other message types.
The server can simply follow the state machine of the protocol and process the messages in turn,
regardless of whether the client uses pipelining or not.
The MUX/DEMUX layer (Chapter~\ref{chapter:multiplexer}) guarantees
that messages of the same mini protocol are delivered in transmission order.
Therefore, the client can determine which response belongs to which request.

The MUX/DEMUX layer also provides a fixed-size buffer between the egress of DEMUX and the ingress
of mini protocol thread.
The size of this buffer is a protocol parameter that determines how many messages
a client can send before waiting for a reply from the server (see Section~\ref{mux-flow-control}).
The protocol requires that a client must never cause an overrun of these buffers on a server node.
If a message arrives at the server that would cause the buffer to overrun,
the server treats this case as a protocol violation of the peer
(and closes the connection to the peer).

\section{Node-to-node protocol}
\label{section:node-to-node-protocol}
\haddockref{Ouroboros.Network.NodeToNode}{ouroboros-network/Ouroboros-Network-NodeToNode}\newline
\haddockref{Ouroboros.Network.NodeToNode.Version}{ouroboros-network-api/Ouroboros-Network-NodeToNode-Version}\newline

The \textit{node-to-node protocol} consists of the following protocols:
\begin{itemize}
  \item \textit{chain-sync mini-protocol} for headers (section~\ref{chain-sync-protocol})
  \item \textit{block-fetch mini-protocol} (section~\ref{block-fetch-protocol})
  \item \textit{tx-submission mini-protocol};  from \texttt{NodeToNodeV\_6} the version
    2 is used  (section~\ref{tx-submission-protocol2})
  \item \textit{keep alive mini-protocol}; from \texttt{NodeToNodeV\_3} (section~\ref{keep-alive-protocol})
  \item \textit{peer-sharing mini-protocol}; from \texttt{NodeToNodeV\_11} (section~\ref{peer-sharing-protocol})
\end{itemize}
Currently supported versions of the \textit{node-to-node protocol} are listed
in table~\ref{table:node-to-node-protocol-versions}.
\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{version}         & \header{description} \\\hline
      \texttt{NodeToNodeV\_14} & No changes, identifies Plomin HF nodes mandatory on mainnet as of 2025.01.29\\
      \texttt{NodeToNodeV\_15} & No changes, identifies nodes which support SRV records\\
    \end{tabular}
    \caption{Node-to-node protocol versions}
    \label{table:node-to-node-protocol-versions}
  \end{center}
\end{figure}
\newline
Previously supported node-to-node versions are listed in table \ref{table:historical-node-to-node-protocol-versions}.

\subsection{Node-to-node mux mini-protocol numbers}
The following table~\ref{table:node-to-node-protocol-numbers} shows mux mini-protocol numbers
assigned to each node-to-node mini-protocol.
\begin{table}[ht]
  \begin{center}
    \begin{tabular}{l|c}
      \header{mini-protocol}                                             & \header{mini-protocol number} \\\hline
      \hyperref[handshake-protocol]{Handshake}                           & $0$  \\
      \hyperref[chain-sync-protocol]{Chain-Sync}                         & $2$  \\
      \hyperref[block-fetch-protocol]{Block-Fetch}                       & $3$  \\
      \hyperref[tx-submission-protocol2]{Tx-Submission}                  & $4$  \\
      \hyperref[keep-alive-protocol]{Keep-Alive}                         & $8$  \\
      \hyperref[peer-sharing-protocol]{Peer-Sharing} \small{(optional)}  & $10$ \\
    \end{tabular}
  \end{center}
  \caption{Node-to-node protocol numbers}
  \label{table:node-to-node-protocol-numbers}
\end{table}

\subsection{Node-to-node mux ingress buffer size limits}

Ingress buffer is the buffer which holds received data for a given
mini-protocol.  It is an internal detail of the multiplexer. Each
implementation should define its ingress buffer size limits.  Here we specify
the default choices we made for Cardano Node.  These limits depend on how much
pipelining depth a given mini-protocol can do.  This is an internal
implementation detail since the amount of pipelining is controlled by the peer
who owns its ingress buffer.

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{l|r}
      \header{mini-protocol}                            & \header{ingress size limit in bytes} \\\hline
      \hyperref[handshake-protocol]{Handshake}          &  - \\
      \hyperref[chain-sync-protocol]{Chain-Sync}        &  $462\,000$ \\
      \hyperref[block-fetch-protocol]{Block-Fetch}      &  $230\,686\,940$ \\
      \hyperref[tx-submission-protocol2]{Tx-Submission} &  $721\,424$ \\
      \hyperref[keep-alive-protocol]{Keep-Alive}        &  $1\,408$ \\
      \hyperref[peer-sharing-protocol]{Peer-Sharing}    &  $5\,760$ \\
    \end{tabular}
    \caption{Mux ingress buffer sizes for each mini-protocol}
    \label{table:node-to-node-ingress-buffer-limits}
  \end{center}
\end{table}

\section{Node-to-client protocol}
\label{section:node-to-client-protocol}
\haddockref{Ouroboros.Network.NodeToClient}{ouroboros-network/Ouroboros-Network-NodeToClient}\newline
\haddockref{Ouroboros.Network.NodeToClient.Version}{ouroboros-network-api/Ouroboros-Network-NodeToClient-Version}\newline

The \textit{node-to-client protocol} consists of the following protocols:
\begin{itemize}
  \item \textit{chain-sync mini-protocol} for blocks (section~\ref{chain-sync-protocol})
  \item \textit{local-tx-submission mini-protocol} (section~\ref{local-tx-submission-protocol})
  \item \textit{local-state-query mini-protocol}; from version \texttt{NodeToClientV\_2} (section~\ref{local-state-query-protocol})
  \item \textit{local tx-monitor mini-protocol}; from version \texttt{NodeToClientV\_12} (section~\ref{local-tx-monitor-protocol})
\end{itemize}
Supported versions of \textit{node-to-client protocol} are listed in
table~\ref{table:node-to-client-protocol-versions}.
\begin{figure}[h]
  \begin{center}
    \begin{tabular}{l|l}
      \header{version} & \header{description} \\\hline
      \texttt{NodeToClientV\_16} & Conway era, \texttt{ImmutableTip} and \texttt{GetStakeDelegDeposits} queries \\
      \texttt{NodeToClientV\_17} & \texttt{GetProposals}, \texttt{GetRatifyState} queries \\
      \texttt{NodeToClientV\_18} & \texttt{GetFuturePParams} query \\
      \texttt{NodeToClientV\_19} & \texttt{GetBigLedgerPeerSnapshot} query\\
      \texttt{NodeToClientV\_20} & \texttt{QueryStakePoolDefaultVote} query; \\
                                 & added \texttt{MsgGetMeasures} and \texttt{MsgReplyGetMeasures} queries \\
      \texttt{NodeToClientV\_21} & new codecs for \texttt{PParams} and \texttt{CompactGenesis} \\
    \end{tabular}
    \caption{Node-to-client protocol versions}
    \label{table:node-to-client-protocol-versions}
  \end{center}
\end{figure}
\newline
Previously supported node-to-client versions are listed in table \ref{table:historical-node-to-client-protocol-versions}.

\subsection{Node-to-client mux mini-protocol numbers}
The following table~\ref{table:node-to-client-protocol-numbers} show mux mini-protocol numbers
assigned to each node-to-client mini-protocol.
\begin{table}[ht]
  \begin{center}
    \begin{tabular}{l|c}
      \header{mini-protocol}                                       & \header{mini-protocol number} \\\hline
      \hyperref[handshake-protocol]{Handshake}                     & $0$ \\
      \hyperref[chain-sync-protocol]{Chain-Sync}                   & $5$ \\
      \hyperref[local-tx-submission-protocol]{Local Tx-Submission} & $6$ \\
      \hyperref[local-state-query-protocol]{Local State Query}     & $7$ \\
      \hyperref[local-tx-monitor-protocol]{Local Tx-Monitor}       & $9$ \\
    \end{tabular}
  \end{center}
  \caption{Node-to-client protocol numbers}
  \label{table:node-to-client-protocol-numbers}
\end{table}

\subsection{Node-to-client mux ingress buffer size limits}

All \textit{node-to-client protocols} are using very large ingress buffer size
limits of $4\,294\,967\,295$ bytes, effectively there are no size limits.
